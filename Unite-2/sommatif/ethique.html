<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>L'éthique</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- Les polices de Google -->
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400;1,700&family=Merriweather:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
        <!-- Le style standard -->
        <link rel="stylesheet" href="style.css">
        <!-- Les styles des citations -->
        <link rel="stylesheet" href="citation.css">
        <!-- Les styles des figures -->
        <link rel="stylesheet" href="images.css">
    </head>
    <body>
        <div class="wrapper_flex">
            <header id="au_cote">
                <h2>LE PROGRÈS DE L'INTELLIGENCE ARTIFICIELLE</h2>
                <nav class="navi" id="navi-petit">Menu</nav>
            </header>

            <nav class="navi_grand" id="navi-grand">
                <ul>
                    <li>
                        <a href="index.html">
                            &#127968;
                        </a>
                    </li>
                    <li>
                        <a href="ordi.html">
                            Les composantes ordinateurs
                        </a>
                    </li>
                    <li>
                        <a href="voiture.html">
                            L'autoconduite des voitures
                        </a>
                    </li>
                    <li>
                        <a href="iot.html">
                            L'Internet des Choses
                        </a>
                    </li>
                    <li>
                        <a href="ethique.html">
                            L'éthique de l'IA
                        </a>
                    </li>
                    <li>
                        <a href="conclusion.html">
                            Conclusion
                        </a>
                    </li>
                    <li>
                        <a href="bibliographie.html">
                            Bibliographie
                        </a>
                    </li>
                    <li>
                        <a id="navi-quitter" href="#" style="color:red;">X</a>
                    </li>
                </ul>
            </nav>

            <main>
                <h1>Quels enjeux d'éthiques l'IA pose-t-elle?</h1>
                <figure id="ethicIA">
                    <img src="ethicIA.jpg" alt="https://www.google.com/url?sa=i&url=https%3A%2F%2Fdevclass.com%2F2020%2F03%2F02%2Fvatican-signs-up-ibm-and-microsoft-as-ai-ethics-apostles%2F&psig=AOvVaw0vWAQUcT5c7Qr6ES4UDXDS&ust=1617811374327000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCJiR_7mH6u8CFQAAAAAdAAAAABAD">
                    <figcaption>Quel est le prix à payer?</figcaption>
                </figure>
                <p>
                Beaucoup des applications issues de l’IA nécessitent la récolte, l’analyse et, souvent, le stockage d’information qui relève de la vie privée des utilisateurs. D’une part, il y a des personnes qui ne veulent pas user de ses technologies; on parle donc de situations où des informations personnelles sont récoltées sans consentement, voire à l’insu des gens. D’autre part, il y a des personnes qui sont d’accord de bénéficier des progrès futuristes. Toutefois, elles ne veulent pas que leurs informations soient identifiables, ni compilées.
                </p>
                <div class="citation">
                    <span>
                        [Artificial intelligence (AI) and robotics] have raised fundamental questions about what we should do with these systems, what the systems themselves should do, what risks they involve, and how we can control these. (Müller, 2020)
                    </span>
                </div>

                <p>
                Les soucis pointent vers les risques qu’engendre la récolte de données par les compagnies développant les services d’intelligence artificielle. D’abord, il y a le manque de transparence : le fait de récolter sans aviser ou bien de récolter d’une manière qui, selon l’opinion de plusieurs, devrait être interdit. De plus, il y a le contrôle de l’information et le pouvoir qu’il apporte à ceux qui visent à dominer le monde de l’IA. Ce risque se manifeste dans la vente des données personnelles, possiblement à des malfaiteurs, et dans la manipulation des publicités et produits auxquels nous sommes exposés, sur Internet par exemple.
                </p>
                <p>
                On parle du droit « de demeurer inconnu », mais les progrès de l’IA soulèvent des questions inquiétantes à propos des motivations qui poussent les compagnies à récolter nos informations personnelles. Si nous voulons nous protéger et éviter de créer un monde où la meilleure compagnie est celle qui a le plus grand accès aux données personnelles des gens, nous devons faire valoir nos droits de protection au niveau législatif. Une solution possible viendrait certes du gouvernement et des législatures mises en place pour maintenir la sécurité de la population générale en jonction avec des chercheurs qui établissent des normes d’éthiques plus robustes.
                </p>
            </main>
        </div>
        <!-- Le script pour ouvrir et fermer le tableau de contenu -->
        <script src="navigation.js"></script>
    </body>
</html>
